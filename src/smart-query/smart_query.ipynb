{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Query\n",
    "This Notebook allows user to query a random piece of information from SumDB first. If the information is found in SumDB, it will then go to LogosCluster to find the full-length article. Otherwise, return nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.11/site-packages (2.9.9)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (13.8.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich) (2.16.1)\n",
      "Collecting numpy>=1.19.5 (from scikit-learn)\n",
      "  Downloading numpy-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-1.4.2 numpy-2.1.0 scikit-learn-1.5.1 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2-binary rich scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from psycopg2 import sql\n",
    "from rich import print\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message: str) -> None:\n",
    "    \"\"\"\n",
    "    Logs a message to the console.\n",
    "    \"\"\"\n",
    "    print(message)\n",
    "    with open(\"sumdb_log.txt\", \"a\") as log_file:\n",
    "        log_file.write(message + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names(conn, table):\n",
    "    \"\"\"\n",
    "    Fetches and logs the column names of a specified table.\n",
    "    \"\"\"\n",
    "    query = sql.SQL(\"\"\"\n",
    "        SELECT column_name \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_name = %s\n",
    "        ORDER BY ordinal_position;\n",
    "    \"\"\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query, (table,))\n",
    "    columns = cur.fetchall()\n",
    "    cur.close()\n",
    "    return [col[0] for col in columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform SumDB Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumb db config\n",
    "sumdb_topic = \"logosdb-sumdb\"  # using localhost for now\n",
    "port = \"5432\"\n",
    "dbname = \"db\"  # internal database name\n",
    "username = \"user\"\n",
    "password = \"password\"\n",
    "\n",
    "table = \"test\"  # Name of table to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:22:00</span><span style=\"font-weight: bold\">]</span> Connected to database <span style=\"color: #008000; text-decoration-color: #008000\">'db'</span> on logosdb-sum<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">db:5432</span> as <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m19:22:00\u001b[0m\u001b[1m]\u001b[0m Connected to database \u001b[32m'db'\u001b[0m on logosdb-sum\u001b[1;92mdb:5432\u001b[0m as \u001b[32m'user'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Column names in <span style=\"color: #008000; text-decoration-color: #008000\">'test'</span> table: id, chunkstart, chunkend, topic, summary, updatedat\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Column names in \u001b[32m'test'\u001b[0m table: id, chunkstart, chunkend, topic, summary, updatedat\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Connect to the database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=dbname,\n",
    "    user=username,\n",
    "    password=password,\n",
    "    host=sumdb_topic,\n",
    "    port=port\n",
    ")\n",
    "\n",
    "# Format datetime for readability\n",
    "formatted_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "log(f\"[{formatted_datetime}] Connected to database '{dbname}' on {sumdb_topic}:{port} as '{username}'\")\n",
    "\n",
    "# Get and log column names\n",
    "column_names = get_column_names(conn, table)\n",
    "log(\"Column names in '{}' table: {}\".format(table, \", \".join(column_names)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search(user_query: str, chunk_summary: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the similarity between the user query and a chunk summary using cosine similarity.\n",
    "    \"\"\"\n",
    "    # Create a TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Combine the user query and chunk summary into a list\n",
    "    documents = [user_query, chunk_summary]\n",
    "\n",
    "    # Fit and transform the documents into TF-IDF matrix\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "    # Calculate the cosine similarity between the first and second document\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "\n",
    "    # Return the similarity score as a float\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sumdb_data(conn: psycopg2.extensions.connection, table: str) -> List[Tuple[str]]:\n",
    "    \"\"\"\n",
    "    Fetches all data from the specified table.\n",
    "    \"\"\"\n",
    "    query = sql.SQL(\"SELECT chunkstart, chunkend, topic, summary, updatedat FROM {}\").format(sql.Identifier(table))\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    data = cur.fetchall()\n",
    "    cur.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_vectors_from_summary(chunk_summary: str, user_query: str, threshold: float=0.5) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Find all vectors (rows) in the chunk summary that have a similarity score above the threshold with the user query.\n",
    "    \"\"\"\n",
    "    \n",
    "    relevant_rows = []\n",
    "    current_row = \"\"\n",
    "\n",
    "    # Iterate over each character in the chunk summary\n",
    "    for char in chunk_summary:\n",
    "        # Split summary into rows by newline symbol\n",
    "        if char != '\\n':\n",
    "            current_row += char\n",
    "            continue\n",
    "\n",
    "        # Skip rows that are too short\n",
    "        current_row = current_row.lower().strip()\n",
    "        if len(current_row) <= 5:\n",
    "            current_row = \"\"\n",
    "            continue\n",
    "\n",
    "        score = similarity_search(user_query, current_row)\n",
    "\n",
    "        # only add rows with a similarity score above the threshold\n",
    "        if score > threshold:\n",
    "            relevant_rows.append((current_row, score))\n",
    "\n",
    "        current_row = \"\"\n",
    "\n",
    "    \n",
    "    # Check the last row if it doesn't end with a newline\n",
    "    current_row = current_row.lower().strip()\n",
    "    if len(current_row) > 5:\n",
    "        score = similarity_search(user_query, current_row)\n",
    "        if score > threshold:\n",
    "            relevant_rows.append((current_row, score))\n",
    "    \n",
    "    return relevant_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_vectors_of_all_chunk(raw_data: List[Tuple[str]], user_query: str, threshold: float=0.5) -> List[Tuple[float, str, int, int, str]]:\n",
    "    \"\"\"\n",
    "    Get all relevant vectors from all chunks in the raw data.\n",
    "    (which has similarity > threshold)\n",
    "    \"\"\"\n",
    "\n",
    "    # Do similarity search for each chunk summary\n",
    "    relevant_vectors = []\n",
    "    \n",
    "    progress = 0 # out of 100%\n",
    "    # A chunk is considered relevant if 1 row within it is relevant\n",
    "    for i, chunk_row in enumerate(raw_data):\n",
    "        if i % (len(raw_data) // 10) == 0 and i != 0:\n",
    "            progress += 10\n",
    "            log(f\"Progress: {progress}%, Sum Chunk: {i}/{len(raw_data)}\")\n",
    "        chunk_start, chunk_end, topic, chunk_summary = chunk_row[:4]\n",
    "        valid_rows = get_relevant_vectors_from_summary(chunk_summary, user_query, threshold)\n",
    "        \n",
    "        # Add valid vectors from chunk to relevant_vectors\n",
    "        for row, score in valid_rows:\n",
    "            relevant_vectors.append((score, row, chunk_start, chunk_end, topic))\n",
    "\n",
    "    return relevant_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_detail_articles(relevant_vectors: List[Tuple[float, str, int, int, str]], k_docs: int=5) -> List[Tuple[float, str, str, int, int, str]]:\n",
    "    \"\"\"\n",
    "    Fetches the detailed articles for the top-k most relevant vectors.\n",
    "    \"\"\"\n",
    "    logos_dbname = \"db\"  # internal database name\n",
    "    logos_username = \"user\"\n",
    "    logos_password = \"password\"\n",
    "\n",
    "    logos_table = \"test\"\n",
    "    output = []\n",
    "\n",
    "    # sorted by similarity score\n",
    "    relevant_vectors.sort(key=lambda x: x[0], reverse=True)\n",
    "    for vect in relevant_vectors[:k_docs]:\n",
    "        score, row, chunk_start, chunk_end, node_topic = vect\n",
    "        row_id = int(row.split(\".\")[0]) # extract row id from row string\n",
    "\n",
    "        # connect to db first\n",
    "        logos_conn = psycopg2.connect(\n",
    "            dbname=logos_dbname,\n",
    "            user=logos_username,\n",
    "            password=logos_password,\n",
    "            host=node_topic,\n",
    "        )\n",
    "        \n",
    "        # then do query on topic node\n",
    "        query = sql.SQL(\"\"\"\n",
    "            SELECT question, answer, keywords FROM {} WHERE id = %s\n",
    "        \"\"\").format(sql.Identifier(logos_table))\n",
    "        \n",
    "        with logos_conn.cursor() as cur:\n",
    "            cur.execute(query, (row_id,))\n",
    "            articles = cur.fetchall()\n",
    "            output.append((score, row, articles[0][1], chunk_start, chunk_end, node_topic))\n",
    "            \n",
    "        logos_conn.close()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fetching all data from the SumDB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fetching all data from the SumDB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Data fetched successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Data fetched successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log(\"Fetching all data from the SumDB\")\n",
    "raw_data = get_all_sumdb_data(conn, table)\n",
    "log(\"Data fetched successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Progress: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>%, Sum Chunk: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Progress: \u001b[1;36m10\u001b[0m%, Sum Chunk: \u001b[1;36m45\u001b[0m/\u001b[1;36m450\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Progress: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>%, Sum Chunk: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Progress: \u001b[1;36m20\u001b[0m%, Sum Chunk: \u001b[1;36m90\u001b[0m/\u001b[1;36m450\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Progress: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>%, Sum Chunk: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">135</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Progress: \u001b[1;36m30\u001b[0m%, Sum Chunk: \u001b[1;36m135\u001b[0m/\u001b[1;36m450\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Progress: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>%, Sum Chunk: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">180</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Progress: \u001b[1;36m40\u001b[0m%, Sum Chunk: \u001b[1;36m180\u001b[0m/\u001b[1;36m450\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Progress: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>%, Sum Chunk: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">225</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Progress: \u001b[1;36m50\u001b[0m%, Sum Chunk: \u001b[1;36m225\u001b[0m/\u001b[1;36m450\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Progress: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>%, Sum Chunk: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">270</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Progress: \u001b[1;36m60\u001b[0m%, Sum Chunk: \u001b[1;36m270\u001b[0m/\u001b[1;36m450\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Progress: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>%, Sum Chunk: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">315</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Progress: \u001b[1;36m70\u001b[0m%, Sum Chunk: \u001b[1;36m315\u001b[0m/\u001b[1;36m450\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Progress: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>%, Sum Chunk: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">360</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Progress: \u001b[1;36m80\u001b[0m%, Sum Chunk: \u001b[1;36m360\u001b[0m/\u001b[1;36m450\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Progress: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>%, Sum Chunk: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">405</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Progress: \u001b[1;36m90\u001b[0m%, Sum Chunk: \u001b[1;36m405\u001b[0m/\u001b[1;36m450\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Relevant Chunks\n",
    "user_query = r\"datamaker is a canadian developer and marketer of test data management software datamaker was founded by mathieu pelletier in 2020\"\n",
    "threshold = 0.5\n",
    "relevant_vectors = get_relevant_vectors_of_all_chunk(raw_data, user_query, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> relevant vectors for query <span style=\"color: #008000; text-decoration-color: #008000\">'datamaker is a canadian developer and marketer of test data management software</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">datamaker was founded by mathieu pelletier in 2020'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Found \u001b[1;36m1\u001b[0m relevant vectors for query \u001b[32m'datamaker is a canadian developer and marketer of test data management software\u001b[0m\n",
       "\u001b[32mdatamaker was founded by mathieu pelletier in 2020'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Print first <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> relevant vectors:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Print first \u001b[1;36m5\u001b[0m relevant vectors:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Relevant Vector <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Relevant Vector \u001b[1;36m1\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Topic: Computer-Science, Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5827386398810945</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Topic: Computer-Science, Score: \u001b[1;36m0.5827386398810945\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Vector Content: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224501</span>. datamaker datamaker is a canadian developer and marketer of test data management software \n",
       "datamaker was founded by mathieu pelletier in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2020</span>  its products and services aim to provide tools for generating \n",
       "synthetic data datamaker is a canadian developer and marketer of test data management software datamaker was \n",
       "founded by mathieu pelletier in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2020</span>  its products and services aim to provide tools for generating synthetic data \n",
       "history  the company was started in stealth mode in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2018</span> the idea was developed inside a big data project the \n",
       "software was publically launched in the september <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2021</span> reasons challenges faced the company has receive a preseed \n",
       "funding of 100k  the startup is part of startup montreal ecosystem   software and services  the software is \n",
       "available in aws marketplace as an ec2 ami  there is also a offering on in azure the platform is available as a \n",
       "standalone application or in the cloud  references  categorysoftware forcetoc\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Vector Content: \u001b[1;36m224501\u001b[0m. datamaker datamaker is a canadian developer and marketer of test data management software \n",
       "datamaker was founded by mathieu pelletier in \u001b[1;36m2020\u001b[0m  its products and services aim to provide tools for generating \n",
       "synthetic data datamaker is a canadian developer and marketer of test data management software datamaker was \n",
       "founded by mathieu pelletier in \u001b[1;36m2020\u001b[0m  its products and services aim to provide tools for generating synthetic data \n",
       "history  the company was started in stealth mode in \u001b[1;36m2018\u001b[0m the idea was developed inside a big data project the \n",
       "software was publically launched in the september \u001b[1;36m2021\u001b[0m reasons challenges faced the company has receive a preseed \n",
       "funding of 100k  the startup is part of startup montreal ecosystem   software and services  the software is \n",
       "available in aws marketplace as an ec2 ami  there is also a offering on in azure the platform is available as a \n",
       "standalone application or in the cloud  references  categorysoftware forcetoc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not relevant_vectors:\n",
    "    log(f\"No relevant vectors found for query '{user_query}'\")\n",
    "else:\n",
    "    log(f\"Found {len(relevant_vectors)} relevant vectors for query '{user_query}'\")\n",
    "    log(f\"Print first 5 relevant vectors:\")\n",
    "    for i, chunk in enumerate(relevant_vectors[:5]):\n",
    "        score, row, chunk_start, chunk_end, topic = chunk\n",
    "        log(f\"Relevant Vector {i+1}:\")\n",
    "        log(f\"Topic: {topic}, Score: {score}\")\n",
    "        log(f\"Vector Content: {row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.float64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5827386398810945</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'224501. datamaker datamaker is a canadian developer and marketer of test data management software </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">datamaker was founded by mathieu pelletier in 2020  its products and services aim to provide tools for generating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">synthetic data datamaker is a canadian developer and marketer of test data management software datamaker was </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">founded by mathieu pelletier in 2020  its products and services aim to provide tools for generating synthetic data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">history  the company was started in stealth mode in 2018 the idea was developed inside a big data project the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">software was publically launched in the september 2021 reasons challenges faced the company has receive a preseed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">funding of 100k  the startup is part of startup montreal ecosystem   software and services  the software is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">available in aws marketplace as an ec2 ami  there is also a offering on in azure the platform is available as a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">standalone application or in the cloud  references  categorysoftware forcetoc'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'datamaker datamaker is a canadian developer and marketer of test data management software datamaker was </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">founded by mathieu pelletier in 2020  its products and services aim to provide tools for generating synthetic data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">datamaker is a canadian developer and marketer of test data management software datamaker was founded by mathieu </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pelletier in 2020  its products and services aim to provide tools for generating synthetic data  history  the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">company was started in stealth mode in 2018 the idea was developed inside a big data project the software was </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">publically launched in the september 2021 reasons challenges faced the company has receive a preseed funding of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">100k  the startup is part of startup montreal ecosystem   software and services  the software is available in aws </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">marketplace as an ec2 ami  there is also a offering on in azure the platform is available as a standalone </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">application or in the cloud  references  categorysoftware forcetoc'</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224501</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224853</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Computer-Science'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\n",
       "        \u001b[1;35mnp.float64\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0.5827386398810945\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[32m'224501. datamaker datamaker is a canadian developer and marketer of test data management software \u001b[0m\n",
       "\u001b[32mdatamaker was founded by mathieu pelletier in 2020  its products and services aim to provide tools for generating \u001b[0m\n",
       "\u001b[32msynthetic data datamaker is a canadian developer and marketer of test data management software datamaker was \u001b[0m\n",
       "\u001b[32mfounded by mathieu pelletier in 2020  its products and services aim to provide tools for generating synthetic data \u001b[0m\n",
       "\u001b[32mhistory  the company was started in stealth mode in 2018 the idea was developed inside a big data project the \u001b[0m\n",
       "\u001b[32msoftware was publically launched in the september 2021 reasons challenges faced the company has receive a preseed \u001b[0m\n",
       "\u001b[32mfunding of 100k  the startup is part of startup montreal ecosystem   software and services  the software is \u001b[0m\n",
       "\u001b[32mavailable in aws marketplace as an ec2 ami  there is also a offering on in azure the platform is available as a \u001b[0m\n",
       "\u001b[32mstandalone application or in the cloud  references  categorysoftware forcetoc'\u001b[0m,\n",
       "        \u001b[32m'datamaker datamaker is a canadian developer and marketer of test data management software datamaker was \u001b[0m\n",
       "\u001b[32mfounded by mathieu pelletier in 2020  its products and services aim to provide tools for generating synthetic data \u001b[0m\n",
       "\u001b[32mdatamaker is a canadian developer and marketer of test data management software datamaker was founded by mathieu \u001b[0m\n",
       "\u001b[32mpelletier in 2020  its products and services aim to provide tools for generating synthetic data  history  the \u001b[0m\n",
       "\u001b[32mcompany was started in stealth mode in 2018 the idea was developed inside a big data project the software was \u001b[0m\n",
       "\u001b[32mpublically launched in the september 2021 reasons challenges faced the company has receive a preseed funding of \u001b[0m\n",
       "\u001b[32m100k  the startup is part of startup montreal ecosystem   software and services  the software is available in aws \u001b[0m\n",
       "\u001b[32mmarketplace as an ec2 ami  there is also a offering on in azure the platform is available as a standalone \u001b[0m\n",
       "\u001b[32mapplication or in the cloud  references  categorysoftware forcetoc'\u001b[0m,\n",
       "        \u001b[1;36m224501\u001b[0m,\n",
       "        \u001b[1;36m224853\u001b[0m,\n",
       "        \u001b[32m'Computer-Science'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get top k articles\n",
    "k = 5\n",
    "detail_articles = find_detail_articles(relevant_vectors, k)\n",
    "\n",
    "print(detail_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
